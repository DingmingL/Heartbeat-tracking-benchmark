{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ef5e5ce",
   "metadata": {},
   "source": [
    "# Metrics calculation and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990be7ce",
   "metadata": {},
   "source": [
    "## Metrics calculation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20371275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Sequence, Dict\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    accuracy_score,\n",
    ")\n",
    "from scipy.stats import pearsonr\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db37540",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _to_np(x: Sequence[int]) -> np.ndarray:\n",
    "    \"\"\"Convert to 1D numpy array of int.\"\"\"\n",
    "    arr = np.asarray(x, dtype=np.int64).reshape(-1)\n",
    "    return arr\n",
    "\n",
    "def r2_from_corr(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"Shape mismatch: y_true {y_true.shape}, y_pred {y_pred.shape}\")\n",
    "\n",
    "    r, _ = pearsonr(y_true, y_pred)\n",
    "    return r ** 2\n",
    "\n",
    "def frame_regression_metrics(\n",
    "    y_true: Sequence[int],\n",
    "    y_pred: Sequence[int],\n",
    ") -> Dict[str, float]:\n",
    "    \n",
    "    y_true = _to_np(y_true)\n",
    "    y_pred = _to_np(y_pred)\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2_corr = r2_from_corr(y_true, y_pred)\n",
    "\n",
    "    return {\"MAE\": mae, \"R2_corr\": r2_corr}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7edc36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def first_non_nan(series):\n",
    "    s = series.dropna()\n",
    "    return s.iloc[0] if not s.empty else np.nan\n",
    "\n",
    "def analyze_single_file(path, aggregate_runs=True):\n",
    "    \"\"\"\n",
    "    Adaptively analyze a single result file:\n",
    "    - Load the JSONL file.\n",
    "    - Check which of the four columns (gt_edv / gt_esv / pred_edv / pred_esv) contain valid numeric values.\n",
    "    - Compute the corresponding metrics for any available “GT + Pred” pair:\n",
    "    - If only EDV has a valid pair: compute EDV regression metrics only.\n",
    "    - If only ESV has a valid pair: compute ESV regression metrics only.\n",
    "    Return:\n",
    "        df_num: the original DataFrame with numeric conversion applied, keeping all rows for plotting.\n",
    "        metrics: a dict of metrics, or None.\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    df = pd.read_json(path, lines=True)\n",
    "\n",
    "    for col in [\"gt_edv\", \"gt_esv\", \"pred_edv\", \"pred_esv\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        else:\n",
    "            # still keep non-existing columns for later processing\n",
    "            df[col] = np.nan\n",
    "\n",
    "    # aggregate multiple runs for the same video_index\n",
    "    if aggregate_runs and \"run_id\" in df.columns:\n",
    "                \n",
    "        agg_dict = {}\n",
    "        for col in df.columns:\n",
    "            if col in [\"gt_edv\", \"gt_esv\"]:\n",
    "                agg_dict[col] = first_non_nan\n",
    "            elif col in [\"pred_edv\", \"pred_esv\", \"latency_sec\"]:\n",
    "                agg_dict[col] = \"mean\"\n",
    "            elif col == \"run_id\":\n",
    "                agg_dict[col] = \"nunique\"\n",
    "            else:\n",
    "                agg_dict[col] = \"first\"\n",
    "\n",
    "        df = df.groupby(\"video_index\", as_index=False).agg(agg_dict)\n",
    "\n",
    "    mask_gt_edv   = df[\"gt_edv\"].notna()\n",
    "    mask_gt_esv   = df[\"gt_esv\"].notna()\n",
    "    mask_pred_edv = df[\"pred_edv\"].notna()\n",
    "    mask_pred_esv = df[\"pred_esv\"].notna()\n",
    "\n",
    "    n_gt_edv   = int(mask_gt_edv.sum())\n",
    "    n_gt_esv   = int(mask_gt_esv.sum())\n",
    "\n",
    "    n_pred_edv = int(mask_pred_edv.sum())\n",
    "    n_pred_esv = int(mask_pred_esv.sum())\n",
    "\n",
    "    mask_edv_pair = mask_gt_edv & mask_pred_edv\n",
    "    mask_esv_pair = mask_gt_esv & mask_pred_esv\n",
    "\n",
    "    n_edv_pair = int(mask_edv_pair.sum())\n",
    "    n_esv_pair = int(mask_esv_pair.sum())\n",
    "\n",
    "\n",
    "    if n_edv_pair == 0 and n_esv_pair == 0:\n",
    "        print(f\"[WARN] {path.name}: no EDV or ESV pairs with both GT and Pred. Skip metrics.\")\n",
    "        return df, None\n",
    "\n",
    "    metrics = {\n",
    "        \"frame_errors\": {},\n",
    "    }\n",
    "\n",
    "    # calculate for EDV and ESV separately\n",
    "    if n_edv_pair > 0:\n",
    "        edv_true = df.loc[mask_edv_pair, \"gt_edv\"].values\n",
    "        edv_pred = df.loc[mask_edv_pair, \"pred_edv\"].values\n",
    "\n",
    "        metrics[\"frame_errors\"][\"EDV\"] = frame_regression_metrics(edv_true, edv_pred)\n",
    "\n",
    "\n",
    "    if n_esv_pair > 0:\n",
    "        esv_true = df.loc[mask_esv_pair, \"gt_esv\"].values\n",
    "        esv_pred = df.loc[mask_esv_pair, \"pred_esv\"].values\n",
    "\n",
    "        metrics[\"frame_errors\"][\"ESV\"] = frame_regression_metrics(esv_true, esv_pred)\n",
    "\n",
    "    return df, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a2d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_binary_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: 1D numpy array, values in {0,1}\n",
    "    Returns:\n",
    "      - accuracy, precision, recall, f1\n",
    "      - confusion matrix (tn, fp, fn, tp)\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = np.asarray(y_pred).astype(int)\n",
    "\n",
    "    assert set(np.unique(y_true)).issubset({0, 1})\n",
    "    assert set(np.unique(y_pred)).issubset({0, 1})\n",
    "\n",
    "    tp = int(((y_true == 1) & (y_pred == 1)).sum())\n",
    "    tn = int(((y_true == 0) & (y_pred == 0)).sum())\n",
    "    fp = int(((y_true == 0) & (y_pred == 1)).sum())\n",
    "    fn = int(((y_true == 1) & (y_pred == 0)).sum())\n",
    "\n",
    "    total = tp + tn + fp + fn\n",
    "    accuracy = (tp + tn) / total if total > 0 else np.nan\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else np.nan\n",
    "    recall    = tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
    "    if np.isnan(precision) or np.isnan(recall) or (precision + recall) == 0:\n",
    "        f1 = np.nan\n",
    "    else:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    return {\n",
    "        \"n_samples\": int(total),\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"precision\": float(precision) if not np.isnan(precision) else np.nan,\n",
    "        \"recall\": float(recall) if not np.isnan(recall) else np.nan,\n",
    "        \"f1\": float(f1) if not np.isnan(f1) else np.nan,\n",
    "        \"confusion_matrix\": {\n",
    "            \"tn\": tn,\n",
    "            \"fp\": fp,\n",
    "            \"fn\": fn,\n",
    "            \"tp\": tp,\n",
    "        },\n",
    "    }\n",
    "\n",
    "def analyze_single_file_binary(path, aggregate_runs=True):\n",
    "    \"\"\"\n",
    "    For non-medical binary task:\n",
    "\n",
    "    Returns:\n",
    "      - df_num: DataFrame\n",
    "      - metrics: dict or None\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    df = pd.read_json(path, lines=True)\n",
    "\n",
    "    # Convert to numeric, keep NaN\n",
    "    for col in [\"gt_edv\", \"gt_esv\", \"pred_edv\", \"pred_esv\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        else:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    # Determine if this is an EDV or ESV task\n",
    "    n_pred_edv_non_nan = int(df[\"pred_edv\"].notna().sum())\n",
    "    n_pred_esv_non_nan = int(df[\"pred_esv\"].notna().sum())\n",
    "\n",
    "    if n_pred_edv_non_nan > 0 and n_pred_esv_non_nan == 0:\n",
    "        task = \"EDV\"\n",
    "        gt_col = \"gt_edv\"\n",
    "        pred_col = \"pred_edv\"\n",
    "    elif n_pred_esv_non_nan > 0 and n_pred_edv_non_nan == 0:\n",
    "        task = \"ESV\"\n",
    "        gt_col = \"gt_esv\"\n",
    "        pred_col = \"pred_esv\"\n",
    "\n",
    "    print(\n",
    "        f\"[INFO] {path.name}: detected binary task={task}, \"\n",
    "        f\"using GT={gt_col}, PRED={pred_col}\"\n",
    "    )\n",
    "\n",
    "    mask_pair = df[gt_col].notna() & df[pred_col].notna()\n",
    "    n_pair = int(mask_pair.sum())\n",
    "    print(f\"[INFO] {path.name}: raw n_gt_pred_pair={n_pair}\")\n",
    "\n",
    "    if n_pair == 0:\n",
    "        print(f\"[WARN] {path.name}: no valid ({gt_col}, {pred_col}) pairs. Skip metrics.\")\n",
    "        return df, None\n",
    "\n",
    "    # aggregate multiple run_id to video_index level\n",
    "    if aggregate_runs and \"run_id\" in df.columns and \"video_index\" in df.columns:\n",
    "        agg_dict = {}\n",
    "        for col in df.columns:\n",
    "            if col == gt_col:\n",
    "                agg_dict[col] = first_non_nan\n",
    "            elif col == pred_col:\n",
    "                agg_dict[col] = \"mean\"\n",
    "            elif col == \"run_id\":\n",
    "                agg_dict[col] = \"nunique\"\n",
    "            else:\n",
    "                agg_dict[col] = \"first\"\n",
    "\n",
    "        df = df.groupby(\"video_index\", as_index=False).agg(agg_dict)\n",
    "\n",
    "        mask_pair = df[gt_col].notna() & df[pred_col].notna()\n",
    "        n_pair = int(mask_pair.sum())\n",
    "        print(f\"[INFO] {path.name} after aggregation: n_gt_pred_pair={n_pair}\")\n",
    "        if n_pair == 0:\n",
    "            print(\n",
    "                f\"[WARN] {path.name}: no valid ({gt_col}, {pred_col}) pairs \"\n",
    "                \"after aggregation. Skip metrics.\"\n",
    "            )\n",
    "            return df, None\n",
    "\n",
    "    y_true = df.loc[mask_pair, gt_col].values\n",
    "    y_pred = df.loc[mask_pair, pred_col].values\n",
    "\n",
    "    metrics_binary = compute_binary_metrics(y_true, y_pred)\n",
    "\n",
    "    print(\n",
    "        f\"[METRICS] {path.name} [{task}]: \"\n",
    "        f\"n={metrics_binary['n_samples']}, \"\n",
    "        f\"acc={metrics_binary['accuracy']:.4f}, \"\n",
    "        f\"prec={metrics_binary['precision']:.4f}, \"\n",
    "        f\"rec={metrics_binary['recall']:.4f}, \"\n",
    "        f\"f1={metrics_binary['f1']:.4f}\"\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        \"task\": task,\n",
    "        \"binary_metrics\": metrics_binary,\n",
    "    }\n",
    "    return df, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84081d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def out_pattern_region(prompt_end=\"esv_edv\"):\n",
    "    if prompt_end == \"edv_esv\":\n",
    "        return re.compile(r\"LARGEST_AREA_INDEX\\s*=\\s*(-?\\d+)\\s*,\\s*SMALLEST_AREA_INDEX\\s*=\\s*(-?\\d+)\", re.IGNORECASE)\n",
    "    elif prompt_end == \"esv_edv\":\n",
    "        return re.compile(r\"SMALLEST_AREA_INDEX\\s*=\\s*(-?\\d+)\\s*,\\s*LARGEST_AREA_INDEX\\s*=\\s*(-?\\d+)\", re.IGNORECASE)\n",
    "    elif prompt_end == \"edv\":\n",
    "        return re.compile(r\"LARGEST_AREA_INDEX\\s*=\\s*(-?\\d+)\", re.IGNORECASE)\n",
    "    elif prompt_end == \"esv\":\n",
    "        return re.compile(r\"SMALLEST_AREA_INDEX\\s*=\\s*(-?\\d+)\", re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a0e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def analyze_single_file_region(path, tol_frame=3, aggregate_runs=True):\n",
    "    \"\"\"\n",
    "    Adaptive analysis of a single result file:\n",
    "      1. Read jsonl\n",
    "      2. Determine which of the columns gt_edv / gt_esv / pred_edv / pred_esv have valid numeric values\n",
    "      3. Calculate corresponding metrics for columns with \"GT + Pred pairs\"\n",
    "         - Only EDV has pairs -> calculate regression and hit_rate for EDV only\n",
    "         - Only ESV has pairs -> calculate regression and hit_rate for ESV only\n",
    "         - Both columns have pairs -> additionally calculate pair_hit_rate\n",
    "      4. Returns:\n",
    "         - df_num: numeric and aggregated DataFrame\n",
    "         - metrics: dict or None\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    filename = path.name\n",
    "    df = pd.read_json(path, lines=True)\n",
    "\n",
    "    for col in [\"gt_edv\", \"gt_esv\", \"pred_edv\", \"pred_esv\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        else:\n",
    "            # still keep non-existing columns for later processing\n",
    "            df[col] = np.nan\n",
    "\n",
    "    if \"segmented\" in filename:\n",
    "        task = filename.replace(\"results_\", \"\").replace(\"_video_random_seed\", \"\").replace(\"_segmented_echo\", \"\").replace(\".jsonl\", \"\")\n",
    "    else:\n",
    "        task = filename.replace(\"results_\", \"\").replace(\"_video_random_seed\", \"\").replace(\"_echo\", \"\").replace(\".jsonl\", \"\")\n",
    "    seed = task.split(\"_\")[-1]\n",
    "\n",
    "    task_end = task.split(\"_\", 1)[-1].replace(f\"_{seed}\", \"\")\n",
    "    print(f\"[INFO] {path.name}: detected task_end={task_end}, seed={seed}\")\n",
    "    outpat = out_pattern_region(prompt_end=task_end)\n",
    "        \n",
    "    index = 0\n",
    "    for row in list(df['output']):\n",
    "        match = outpat.search(row)\n",
    "        if match:\n",
    "            if task_end == \"edv_esv\":\n",
    "                edv_index = int(match.group(1))\n",
    "                esv_index = int(match.group(2))\n",
    "                df.at[index, 'pred_edv'] = edv_index\n",
    "                df.at[index, 'pred_esv'] = esv_index\n",
    "            elif task_end == \"esv_edv\":\n",
    "                esv_index = int(match.group(1))\n",
    "                edv_index = int(match.group(2))\n",
    "                df.at[index, 'pred_edv'] = edv_index\n",
    "                df.at[index, 'pred_esv'] = esv_index\n",
    "            elif task_end == \"edv\":\n",
    "                edv_index = int(match.group(1))\n",
    "                df.at[index, 'pred_edv'] = edv_index\n",
    "            elif task_end == \"esv\":\n",
    "                esv_index = int(match.group(1))\n",
    "                df.at[index, 'pred_esv'] = esv_index\n",
    "        index += 1\n",
    "\n",
    "    # aggregate multiple runs for the same video_index\n",
    "    if aggregate_runs and \"run_id\" in df.columns:\n",
    "                \n",
    "        agg_dict = {}\n",
    "        for col in df.columns:\n",
    "            if col in [\"gt_edv\", \"gt_esv\"]:\n",
    "                agg_dict[col] = first_non_nan\n",
    "            elif col in [\"pred_edv\", \"pred_esv\", \"latency_sec\"]:\n",
    "                agg_dict[col] = \"mean\"\n",
    "            elif col == \"run_id\":\n",
    "                agg_dict[col] = \"nunique\"\n",
    "            else:\n",
    "                agg_dict[col] = \"first\"\n",
    "\n",
    "        df = df.groupby(\"video_index\", as_index=False).agg(agg_dict)\n",
    "\n",
    "    mask_gt_edv   = df[\"gt_edv\"].notna()\n",
    "    mask_gt_esv   = df[\"gt_esv\"].notna()\n",
    "    mask_pred_edv = df[\"pred_edv\"].notna()\n",
    "    mask_pred_esv = df[\"pred_esv\"].notna()\n",
    "\n",
    "    n_gt_edv   = int(mask_gt_edv.sum())\n",
    "    n_gt_esv   = int(mask_gt_esv.sum())\n",
    "\n",
    "    n_pred_edv = int(mask_pred_edv.sum())\n",
    "    n_pred_esv = int(mask_pred_esv.sum())\n",
    "\n",
    "    mask_edv_pair = mask_gt_edv & mask_pred_edv\n",
    "    mask_esv_pair = mask_gt_esv & mask_pred_esv\n",
    "\n",
    "    n_edv_pair = int(mask_edv_pair.sum())\n",
    "    n_esv_pair = int(mask_esv_pair.sum())\n",
    "\n",
    "    print(f\"[INFO] {path.name}: \"\n",
    "          f\"n_gt_edv={n_gt_edv}, n_pred_edv={n_pred_edv}, n_edv_pair={n_edv_pair}; \"\n",
    "          f\"n_gt_esv={n_gt_esv}, n_pred_esv={n_pred_esv}, n_esv_pair={n_esv_pair}\")\n",
    "\n",
    "    if n_edv_pair == 0 and n_esv_pair == 0:\n",
    "        print(f\"[WARN] {path.name}: no EDV or ESV pairs with both GT and Pred. Skip metrics.\")\n",
    "        return df, None\n",
    "    \n",
    "    elif n_edv_pair == 1:\n",
    "        print(f\"[WARN] {path.name}: only one EDV pairs with both GT and Pred. Skip metrics.\")\n",
    "        return df, None\n",
    "    \n",
    "    elif n_esv_pair == 1:\n",
    "        print(f\"[WARN] {path.name}: only one ESV pairs with both GT and Pred. Skip metrics.\")\n",
    "        return df, None\n",
    "\n",
    "    metrics = {\n",
    "        \"frame_errors\": {},\n",
    "        \"seed\": seed,\n",
    "    }\n",
    "\n",
    "    # calculate for EDV and ESV separately\n",
    "    if n_edv_pair > 1:\n",
    "        edv_true = df.loc[mask_edv_pair, \"gt_edv\"].values\n",
    "        edv_pred = df.loc[mask_edv_pair, \"pred_edv\"].values\n",
    "\n",
    "        metrics[\"frame_errors\"][\"EDV\"] = frame_regression_metrics(edv_true, edv_pred)\n",
    "\n",
    "    if n_esv_pair > 1:\n",
    "        esv_true = df.loc[mask_esv_pair, \"gt_esv\"].values\n",
    "        esv_pred = df.loc[mask_esv_pair, \"pred_esv\"].values\n",
    "\n",
    "        metrics[\"frame_errors\"][\"ESV\"] = frame_regression_metrics(esv_true, esv_pred)\n",
    "\n",
    "    return df, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ab5d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_single_file_binary_region(path, aggregate_runs=True):\n",
    "    \"\"\"\n",
    "    For non-medical binary task\n",
    "\n",
    "    Returns:\n",
    "      - df_num: DataFrame\n",
    "      - metrics: dict or None\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    filename = path.name\n",
    "    df = pd.read_json(path, lines=True)\n",
    "\n",
    "    for col in [\"gt_edv\", \"gt_esv\", \"pred_edv\", \"pred_esv\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        else:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    if \"segmented\" in filename:\n",
    "        task = filename.replace(\"results_\", \"\").replace(\"_frame_random_seed\", \"\").replace(\"_segmented_echo\", \"\").replace(\".jsonl\", \"\")\n",
    "    else:\n",
    "        task = filename.replace(\"results_\", \"\").replace(\"_frame_random_seed\", \"\").replace(\"_echo\", \"\").replace(\".jsonl\", \"\")\n",
    "    seed = task.split(\"_\")[-1]\n",
    "\n",
    "    task_end = task.split(\"_\", 1)[-1].replace(f\"_{seed}\", \"\")\n",
    "    outpat = out_pattern_region(prompt_end=task_end)\n",
    "        \n",
    "    index = 0\n",
    "    for row in list(df['output']):\n",
    "        match = outpat.search(row)\n",
    "        if match:\n",
    "            if task_end == \"edv_esv\":\n",
    "                edv_index = int(match.group(1))\n",
    "                esv_index = int(match.group(2))\n",
    "                df.at[index, 'pred_edv'] = edv_index\n",
    "                df.at[index, 'pred_esv'] = esv_index\n",
    "            elif task_end == \"esv_edv\":\n",
    "                esv_index = int(match.group(1))\n",
    "                edv_index = int(match.group(2))\n",
    "                df.at[index, 'pred_edv'] = edv_index\n",
    "                df.at[index, 'pred_esv'] = esv_index\n",
    "            elif task_end == \"edv\":\n",
    "                edv_index = int(match.group(1))\n",
    "                df.at[index, 'pred_edv'] = edv_index\n",
    "            elif task_end == \"esv\":\n",
    "                esv_index = int(match.group(1))\n",
    "                df.at[index, 'pred_esv'] = esv_index\n",
    "        index += 1\n",
    "\n",
    "    n_pred_edv_non_nan = int(df[\"pred_edv\"].notna().sum())\n",
    "    n_pred_esv_non_nan = int(df[\"pred_esv\"].notna().sum())\n",
    "\n",
    "    if n_pred_edv_non_nan > 0 and n_pred_esv_non_nan == 0:\n",
    "        task = \"EDV\"\n",
    "        gt_col = \"gt_edv\"\n",
    "        pred_col = \"pred_edv\"\n",
    "    elif n_pred_esv_non_nan > 0 and n_pred_edv_non_nan == 0:\n",
    "        task = \"ESV\"\n",
    "        gt_col = \"gt_esv\"\n",
    "        pred_col = \"pred_esv\"\n",
    "\n",
    "    print(\n",
    "        f\"[INFO] {path.name}: detected binary task={task}, \"\n",
    "        f\"using GT={gt_col}, PRED={pred_col}\"\n",
    "    )\n",
    "\n",
    "    mask_pair = df[gt_col].notna() & df[pred_col].notna()\n",
    "    n_pair = int(mask_pair.sum())\n",
    "    print(f\"[INFO] {path.name}: raw n_gt_pred_pair={n_pair}\")\n",
    "\n",
    "    if n_pair == 0:\n",
    "        print(f\"[WARN] {path.name}: no valid ({gt_col}, {pred_col}) pairs. Skip metrics.\")\n",
    "        return df, None\n",
    "\n",
    "    # aggregate multiple runs for the same video_index\n",
    "    if aggregate_runs and \"run_id\" in df.columns and \"video_index\" in df.columns:\n",
    "        agg_dict = {}\n",
    "        for col in df.columns:\n",
    "            if col == gt_col:\n",
    "                agg_dict[col] = first_non_nan\n",
    "            elif col == pred_col:\n",
    "                # multiple runs: average then round -> 0/1. Equivalent to majority voting\n",
    "                agg_dict[col] = \"mean\"\n",
    "            elif col == \"run_id\":\n",
    "                agg_dict[col] = \"nunique\"\n",
    "            else:\n",
    "                agg_dict[col] = \"first\"\n",
    "\n",
    "        df = df.groupby(\"video_index\", as_index=False).agg(agg_dict)\n",
    "\n",
    "        # construct valid pair mask again\n",
    "        mask_pair = df[gt_col].notna() & df[pred_col].notna()\n",
    "        n_pair = int(mask_pair.sum())\n",
    "        print(f\"[INFO] {path.name} after aggregation: n_gt_pred_pair={n_pair}\")\n",
    "        if n_pair == 0:\n",
    "            print(\n",
    "                f\"[WARN] {path.name}: no valid ({gt_col}, {pred_col}) pairs \"\n",
    "                \"after aggregation. Skip metrics.\"\n",
    "            )\n",
    "            return df, None\n",
    "\n",
    "    # final arrays for metrics\n",
    "    y_true = df.loc[mask_pair, gt_col].values\n",
    "    y_pred = df.loc[mask_pair, pred_col].values\n",
    "\n",
    "    metrics_binary = compute_binary_metrics(y_true, y_pred)\n",
    "\n",
    "    print(\n",
    "        f\"[METRICS] {path.name} [{task}]: \"\n",
    "        f\"n={metrics_binary['n_samples']}, \"\n",
    "        f\"acc={metrics_binary['accuracy']:.4f}, \"\n",
    "        f\"prec={metrics_binary['precision']:.4f}, \"\n",
    "        f\"rec={metrics_binary['recall']:.4f}, \"\n",
    "        f\"f1={metrics_binary['f1']:.4f}\"\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        \"task\": task,\n",
    "        \"binary_metrics\": metrics_binary,\n",
    "    }\n",
    "    return df, metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c11b5ef",
   "metadata": {},
   "source": [
    "## metrics calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc2f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage\n",
    "file_dir = \"your/path/to/results/\"\n",
    "dir_list = [\n",
    "    'LLaVA-NeXT-Video-34B',\n",
    " 'LLaVA-NeXT-Video-7B',\n",
    " 'Qwen3-VL-32B',\n",
    " 'Qwen3-VL-8B',\n",
    " 'gemma-3n',\n",
    " 'llava-interleave'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b9c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname in dir_list:\n",
    "    file_list = os.listdir(os.path.join(file_dir, dirname))\n",
    "    file_list.sort()\n",
    "    print(f\"Processing directory: {dirname}\")\n",
    "\n",
    "    metric_list = []\n",
    "    for filename in file_list:\n",
    "        if \"video\" in filename:\n",
    "            # video: EDV/ESV localization task\n",
    "            result_file = os.path.join(file_dir, dirname, filename)\n",
    "            print(f\"Processing result file: {result_file}\")\n",
    "            df_num, metrics = analyze_single_file(result_file)\n",
    "            \n",
    "        elif \"frame\" in filename:\n",
    "            # frame: binary classification task\n",
    "            result_file = os.path.join(file_dir, dirname, filename)\n",
    "            print(f\"Processing result file: {result_file}\")\n",
    "            df_num, metrics = analyze_single_file_binary(result_file)\n",
    "        \n",
    "        metric_list.append({\n",
    "                \"file_name\": filename,\n",
    "                \"result_file\": result_file,\n",
    "                \"metrics\": metrics,\n",
    "            })\n",
    "\n",
    "    df = pd.json_normalize(metric_list, sep=\"_\")\n",
    "    if \"Qwen\" in dirname:\n",
    "        df['task_type'] = df['file_name'].str.replace(f'results_{dirname}-Instruct_', '').str.replace('echo_', '').str.replace('.jsonl', '')\n",
    "    elif \"NeXT\" in dirname:\n",
    "        df['task_type'] = df['file_name'].str.replace(f'results_{dirname}-hf_', '').str.replace('echo_', '').str.replace('.jsonl', '')\n",
    "    elif \"gemma\" in dirname:\n",
    "        df['task_type'] = df['file_name'].str.replace(f'results_{dirname}-e4b-it_', '').str.replace('echo_', '').str.replace('.jsonl', '')\n",
    "    elif \"interleave\" in dirname:\n",
    "        df['task_type'] = df['file_name'].str.replace(f'results_{dirname}-qwen-7b-hf_', '').str.replace('echo_', '').str.replace('.jsonl', '')\n",
    "    df['model_name'] = dirname\n",
    "\n",
    "    # choose and rename columns for output\n",
    "    df_reg = df[['task_type', 'metrics_frame_errors_EDV_MAE', 'metrics_frame_errors_EDV_R2_corr',\n",
    "            'metrics_frame_errors_ESV_MAE', 'metrics_frame_errors_ESV_RMSE', 'metrics_frame_errors_ESV_R2_score',\n",
    "            'metrics_frame_errors_ESV_R2_corr','model_name']].copy().dropna(how=\"all\", subset=['metrics_frame_errors_EDV_MAE',\n",
    "            'metrics_frame_errors_EDV_R2_corr', 'metrics_frame_errors_ESV_MAE', 'metrics_frame_errors_ESV_RMSE',\n",
    "            'metrics_frame_errors_ESV_R2_score', 'metrics_frame_errors_ESV_R2_corr',])\n",
    "    df_reg.columns = df_reg.columns.str.replace('metrics_frame_errors_', '', regex=False)\n",
    "    df_reg.to_csv(f\"your/path/to/{dirname}_regression_metrics.csv\", index=False)\n",
    "\n",
    "    df_bin = df[['task_type', 'metrics_binary_metrics_accuracy',\n",
    "        'metrics_binary_metrics_precision', 'metrics_binary_metrics_recall',\n",
    "        'metrics_binary_metrics_f1', 'model_name']].copy().dropna(how=\"all\", subset=['metrics_binary_metrics_accuracy',\n",
    "        'metrics_binary_metrics_precision', 'metrics_binary_metrics_recall',\n",
    "        'metrics_binary_metrics_f1',])\n",
    "    df_bin.columns = df_bin.columns.str.replace('metrics_binary_metrics_', '', regex=False)\n",
    "    df_bin.to_csv(f\"your/path/to/{dirname}_binary_metrics.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505aa7bb",
   "metadata": {},
   "source": [
    "## Monte Carlo baseline calculate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c9438",
   "metadata": {},
   "source": [
    "### Frame localization random baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702db647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def random_predict_edv_esv(num_frames):\n",
    "\n",
    "    pred_edv = []\n",
    "    pred_esv = []\n",
    "    for T in num_frames:\n",
    "        pred_edv.append(np.random.randint(0, T))\n",
    "        pred_esv.append(np.random.randint(0, T))\n",
    "    return np.array(pred_edv), np.array(pred_esv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "858f6e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file = \"/home/dili10/scripts/vlm_private/segmented_frame_locate_annotation.csv\"\n",
    "annotations_df = pd.read_csv(annotation_file)\n",
    "\n",
    "video_names = (\n",
    "        annotations_df[\"FileName\"]\n",
    "        .dropna()\n",
    "        .drop_duplicates()\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "videos = video_names[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87603d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_lengths = []\n",
    "gt_edv_list = []\n",
    "gt_esv_list = []\n",
    "for vid_idx, vn in enumerate(videos):\n",
    "    video_data = annotations_df[annotations_df['FileName'] == vn]\n",
    "    \n",
    "    edv_idx = video_data.loc[video_data['Label'] == 'EDV', 'Frame'].iloc[0]\n",
    "    esv_idx = video_data.loc[video_data['Label'] == 'ESV', 'Frame'].iloc[0]\n",
    "    gt_edv_list.append(edv_idx)\n",
    "    gt_esv_list.append(esv_idx)\n",
    "\n",
    "    pick_length = (abs(edv_idx - esv_idx) + 1) * 7 // 3\n",
    "    pick_range = range(int(pick_length))\n",
    "    video_lengths.append(pick_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ffd56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10000\n",
    "mae_edv_random = []\n",
    "mae_esv_random = []\n",
    "\n",
    "for _ in range(n_runs):\n",
    "    pred_edv_r, pred_esv_r = random_predict_edv_esv(video_lengths)\n",
    "    err_edv = np.abs(pred_edv_r - np.array(gt_edv_list))\n",
    "    err_esv = np.abs(pred_esv_r - np.array(gt_esv_list))\n",
    "    mae_edv_random.append(err_edv.mean())\n",
    "    mae_esv_random.append(err_esv.mean())\n",
    "\n",
    "mae_edv_random = np.array(mae_edv_random)\n",
    "mae_esv_random = np.array(mae_esv_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f39c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_random_edv = mae_edv_random.mean()\n",
    "low_95_edv = np.percentile(mae_edv_random, 2.5)\n",
    "high_95_edv = np.percentile(mae_edv_random, 97.5)\n",
    "mean_random_esv = mae_esv_random.mean()\n",
    "low_95_esv = np.percentile(mae_esv_random, 2.5)\n",
    "high_95_esv = np.percentile(mae_esv_random, 97.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db8ea683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(50.92),\n",
       " np.float64(55.64),\n",
       " np.float64(66.32975),\n",
       " np.float64(71.01),\n",
       " np.float64(53.271193999999994),\n",
       " np.float64(68.63563099999999))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_95_edv, high_95_edv, low_95_esv, high_95_esv, mean_random_edv, mean_random_esv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc171202",
   "metadata": {},
   "source": [
    "### Binary task random baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95edf41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "all_df = pd.read_csv(\"your/path/to/binary_results.csv\")\n",
    "\n",
    "def extract_pred_esv(row):\n",
    "    \"\"\"\n",
    "    Use pred_esv column if available; otherwise parse from output text.\n",
    "    \"\"\"\n",
    "\n",
    "    if pd.notna(row[\"pred_esv\"]):\n",
    "        return int(row[\"pred_esv\"])\n",
    "\n",
    "    text = str(row[\"output\"])\n",
    "    m = re.search(r\"SMALLEST_AREA_INDEX\\s*=\\s*([01])\", text)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "\n",
    "    # if neither not found, return NaN\n",
    "    return np.nan\n",
    "\n",
    "# prepare all_df with y_true and y_pred\n",
    "all_df[\"y_true\"] = all_df[\"gt_esv\"].astype(\"float\")  # or astype(int)\n",
    "all_df[\"y_pred\"] = all_df.apply(extract_pred_esv, axis=1)\n",
    "\n",
    "# drop rows with NaN in y_true or y_pred\n",
    "df_clean = all_df.dropna(subset=[\"y_true\", \"y_pred\"]).copy()\n",
    "df_clean[\"y_true\"] = df_clean[\"y_true\"].astype(int)\n",
    "df_clean[\"y_pred\"] = df_clean[\"y_pred\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33310a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def monte_carlo_random_baseline(y_true, n_trials=10000, rng=None):\n",
    "    \"\"\"\n",
    "    Monte Carlo random baseline based on the ground-truth labels y_true.\n",
    "    Random strategy: for each sample, independently predict 0 or 1 with probability 0.5.\n",
    "    Returns:\n",
    "        mean_acc: mean accuracy of the random baseline\n",
    "        ci_low, ci_high: 95% confidence interval\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true, dtype=int)\n",
    "    n = y_true.shape[0]\n",
    "\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(2025)\n",
    "\n",
    "    accs = np.empty(n_trials, dtype=float)\n",
    "    for i in range(n_trials):\n",
    "        y_rand = rng.integers(0, 2, size=n)\n",
    "        accs[i] = (y_rand == y_true).mean()\n",
    "\n",
    "    mean_acc = accs.mean()\n",
    "    ci_low, ci_high = np.percentile(accs, [2.5, 97.5])\n",
    "    return mean_acc, ci_low, ci_high\n",
    "\n",
    "\n",
    "# group by run_id\n",
    "rng = np.random.default_rng(2025)\n",
    "rows = []\n",
    "\n",
    "for name, g in all_df.groupby(\"name\"):\n",
    "    idx_set = set(g[\"video_index\"].tolist())\n",
    "    expected = set(range(100))\n",
    "    if idx_set != expected:\n",
    "        raise ValueError(f\"Missing video_index in group {name}: found {sorted(idx_set)}, expected {sorted(expected)}\")\n",
    "\n",
    "    if 'edv' in name.lower():\n",
    "        y_true = g[\"gt_edv\"].to_numpy()\n",
    "    else:\n",
    "        y_true = g[\"gt_esv\"].to_numpy()\n",
    "    # drop NaN\n",
    "    y_true = y_true[~pd.isna(y_true)].astype(int)\n",
    "\n",
    "    n_samples = len(y_true)\n",
    "    if n_samples == 0:\n",
    "        continue\n",
    "\n",
    "    mean_acc, ci_low, ci_high = monte_carlo_random_baseline(\n",
    "        y_true, n_trials=10000, rng=rng\n",
    "    )\n",
    "\n",
    "    rows.append({\n",
    "        \"name\": name.replace('.', ''),\n",
    "        \"n_samples\": n_samples,\n",
    "        \"random_mean_accuracy\": mean_acc,\n",
    "        \"random_ci_low\": ci_low,\n",
    "        \"random_ci_high\": ci_high,\n",
    "    })\n",
    "\n",
    "mc_df = pd.DataFrame(rows)\n",
    "mc_df.to_csv(\"your/path/to/monte_carlo_random_baseline_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cd0fe0",
   "metadata": {},
   "source": [
    "## metrics plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee196bf",
   "metadata": {},
   "source": [
    "### Binary task plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1dc4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "\n",
    "def plot_metric_all_models_tasks(\n",
    "    df,\n",
    "    metric=\"accuracy\",\n",
    "    task_order=None,\n",
    "    model_order=None,\n",
    "    palette=None,\n",
    "    save_path=None,\n",
    "    show_random=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    df: binary_metrics containing metrics from all models and tasks\n",
    "    metric: \"accuracy\" / \"precision\" / \"recall\" / \"f1\"\n",
    "    task_order: list of task_group to specify order\n",
    "    model_order: list of model_name to specify order\n",
    "    palette: dict or list or None\n",
    "    save_path: str or None\n",
    "    show_random: bool, whether to show random baseline if available\n",
    "    \"\"\"\n",
    "\n",
    "    if task_order is None:\n",
    "        task_order = sorted(df[\"task_group\"].unique())\n",
    "\n",
    "    if model_order is None:\n",
    "        model_order = sorted(df[\"model_name\"].unique())\n",
    "    \n",
    "    pretty_order = [task_pretty[t] for t in task_order]\n",
    "\n",
    "    # palette_dict: pretty_label -> color\n",
    "    if isinstance(palette, dict):\n",
    "        palette_dict = palette\n",
    "    else:\n",
    "        colors = sns.color_palette(palette, n_colors=len(pretty_order)) if palette is not None \\\n",
    "                 else sns.color_palette(n_colors=len(pretty_order))\n",
    "        palette_dict = dict(zip(pretty_order, colors))\n",
    "\n",
    "    plt.figure(figsize=(2.5 * len(model_order), 8))\n",
    "\n",
    "    # boxplot\n",
    "    ax = sns.boxplot(\n",
    "        data=df,\n",
    "        x=\"model_name\",\n",
    "        y=metric,\n",
    "        hue=\"task_group_pretty\",\n",
    "        order=model_order,\n",
    "        hue_order=pretty_order,\n",
    "        palette=palette_dict,\n",
    "        width=0.7,\n",
    "        showfliers=False,\n",
    "        zorder=2,\n",
    "    )\n",
    "\n",
    "    sns.stripplot(\n",
    "        data=df,\n",
    "        x=\"model_name\",\n",
    "        y=metric,\n",
    "        hue=\"task_group_pretty\",\n",
    "        order=model_order,\n",
    "        hue_order=pretty_order,\n",
    "        dodge=True,\n",
    "        alpha=0.4,\n",
    "        linewidth=0,\n",
    "        size=6,\n",
    "        palette=palette_dict,\n",
    "        ax=ax,\n",
    "        zorder=3,\n",
    "    )\n",
    "\n",
    "    if show_random and {\n",
    "        \"random_accuracy\", \"random_ci_low\", \"random_ci_high\"\n",
    "    }.issubset(df.columns) and metric == \"accuracy\":\n",
    "\n",
    "        baseline = (\n",
    "            df[[\n",
    "                \"task_group\",\n",
    "                \"task_group_pretty\",\n",
    "                \"random_accuracy\",\n",
    "                \"random_ci_low\",\n",
    "                \"random_ci_high\",\n",
    "            ]]\n",
    "            .drop_duplicates(subset=[\"task_group\"])\n",
    "        )\n",
    "\n",
    "        # color and style for random baseline\n",
    "        band_color = \"0.9\"\n",
    "        band_alpha = 0.5\n",
    "        line_color = \"0.3\"\n",
    "        line_alpha = 0.9\n",
    "        line_width = 1.5\n",
    "        line_style = \"--\"\n",
    "\n",
    "        # expand along x axis\n",
    "        x_min, x_max = -0.5, len(model_order) - 0.5\n",
    "\n",
    "        for _, row in baseline.iterrows():\n",
    "            pretty = row[\"task_group_pretty\"]\n",
    "            y_mean = row[\"random_accuracy\"]\n",
    "            y_low = row[\"random_ci_low\"]\n",
    "            y_high = row[\"random_ci_high\"]\n",
    "\n",
    "            color = palette_dict.get(pretty, \"grey\")\n",
    "\n",
    "            # CI interval: light band\n",
    "            ax.fill_between(\n",
    "                [x_min, x_max],\n",
    "                [y_low, y_low],\n",
    "                [y_high, y_high],\n",
    "                color=band_color,\n",
    "                alpha=band_alpha,\n",
    "                zorder=0,\n",
    "            )\n",
    "\n",
    "            # Mean line: dashed line\n",
    "            ax.hlines(\n",
    "                y_mean,\n",
    "                x_min,\n",
    "                x_max,\n",
    "                colors=line_color,\n",
    "                linestyles=line_style,\n",
    "                linewidth=line_width,\n",
    "                alpha=line_alpha,\n",
    "                zorder=1,\n",
    "            )\n",
    "\n",
    "            ax._random_band_color = band_color\n",
    "            ax._random_band_alpha = band_alpha\n",
    "            ax._random_line_color = line_color\n",
    "            ax._random_line_style = line_style\n",
    "            ax._random_line_width = line_width\n",
    "\n",
    "    # remove duplicate legend entries\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles = handles[:len(pretty_order)]\n",
    "    labels = labels[:len(pretty_order)]\n",
    "\n",
    "\n",
    "    if hasattr(ax, \"_random_band_color\"):\n",
    "        band_proxy = Patch(\n",
    "            facecolor=ax._random_band_color,\n",
    "            edgecolor=\"none\",\n",
    "            alpha=ax._random_band_alpha,\n",
    "        )\n",
    "        line_proxy = Line2D(\n",
    "            [0], [0],\n",
    "            color=ax._random_line_color,\n",
    "            linestyle=ax._random_line_style,\n",
    "            linewidth=ax._random_line_width,\n",
    "        )\n",
    "\n",
    "        handles = handles + [band_proxy, line_proxy]\n",
    "        labels = labels + [\"Random 95% CI\", \"Random mean\"]\n",
    "\n",
    "    ax.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        title=\"Task\",\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(0.02, 0.98),\n",
    "        borderaxespad=0.,\n",
    "        fontsize=12,\n",
    "        title_fontsize=15,\n",
    "        markerscale=1.2,\n",
    "        handlelength=1.5,\n",
    "    )\n",
    "        \n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(metric.capitalize(), fontsize=15)\n",
    "\n",
    "    plt.xticks(rotation=20, ha=\"center\", fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage\n",
    "binary_metrics = pd.read_csv(\"your/path/to/binary_metrics.csv\")\n",
    "task_order = [\n",
    "    \"edv_frame\",\n",
    "    \"esv_frame\",\n",
    "    \"segmented_edv_frame\",\n",
    "    \"segmented_esv_frame\",\n",
    "    \"non_medical_edv_frame\",\n",
    "    \"non_medical_esv_frame\",\n",
    "]\n",
    "\n",
    "task_pretty = {\n",
    "    \"edv_frame\": \"EDV\",\n",
    "    \"esv_frame\": \"ESV\",\n",
    "    \"segmented_edv_frame\": \"Seg EDV\",\n",
    "    \"segmented_esv_frame\": \"Seg ESV\",\n",
    "    \"non_medical_edv_frame\": \"Non-med EDV\",\n",
    "    \"non_medical_esv_frame\": \"Non-med ESV\",\n",
    "}\n",
    "\n",
    "palette = sns.color_palette(\"Set2\", n_colors=len(task_order))\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "palette_colors = sns.color_palette(\"Set2\", n_colors=len(task_order))\n",
    "\n",
    "palette = {\n",
    "    task_pretty[t]: c\n",
    "    for t, c in zip(task_order, palette_colors)\n",
    "}\n",
    "\n",
    "plot_metric_all_models_tasks(\n",
    "    df=binary_metrics,\n",
    "    metric=\"accuracy\",\n",
    "    task_order=task_order,\n",
    "    model_order=[ 'LLaVA-Interleave','LLaVA-NeXT-Video-7B', 'LLaVA-NeXT-Video-34B','Gemma-3n', \n",
    "                 'Qwen3-VL-8B', 'Qwen3-VL-32B' ],\n",
    "    palette=palette,\n",
    "    save_path=\"t2_accuracy_with_random.png\",\n",
    "    show_random=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37366b97",
   "metadata": {},
   "source": [
    "### Frame localization task plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e30c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "def plot_reg_metric_all_models_tasks(\n",
    "    df,\n",
    "    metric=\"EDV_MAE\",\n",
    "    task_order=None,\n",
    "    model_order=None,\n",
    "    palette=None,\n",
    "    save_path=None,\n",
    "    random_band=None\n",
    "):\n",
    "    \"\"\"\n",
    "    df: regression metrics containing metrics from all models and tasks\n",
    "    metric: \"EDV_MAE\" / \"ESV_MAE\"\n",
    "    task_order: list of task_group to specify order\n",
    "    model_order: list of model_name to specify order\n",
    "    palette: dict or list or None\n",
    "    save_path: str or None\n",
    "    random_band: band info for random baseline, dict of metric -> (mean, low, high)\n",
    "    \"\"\"\n",
    "    if task_order is None:\n",
    "        task_order = sorted(df[\"task_group\"].unique())\n",
    "\n",
    "    if model_order is None:\n",
    "        model_order = sorted(df[\"model_name\"].unique())\n",
    "\n",
    "    sub = df.dropna(subset=[metric]).copy()\n",
    "    if sub.empty:\n",
    "        print(f\"[WARN] metric {metric} has no non-NaN values, skip.\")\n",
    "        return\n",
    "\n",
    "    pretty_order = [\n",
    "        df.loc[df[\"task_group\"] == t, \"task_group_pretty\"].iloc[0]\n",
    "        for t in task_order\n",
    "        if t in sub[\"task_group\"].unique()\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(2.5 * len(model_order), 15))\n",
    "\n",
    "    # boxplot\n",
    "    ax = sns.boxplot(\n",
    "        data=sub,\n",
    "        x=\"model_name\",\n",
    "        y=metric,\n",
    "        hue=\"task_group_pretty\",\n",
    "        order=model_order,\n",
    "        hue_order=pretty_order,\n",
    "        palette=palette,\n",
    "        width=0.7,\n",
    "        fliersize=2,\n",
    "        zorder=2,\n",
    "        showfliers=False,\n",
    "    )\n",
    "\n",
    "    sns.stripplot(\n",
    "        data=sub,\n",
    "        x=\"model_name\",\n",
    "        y=metric,\n",
    "        hue=\"task_group_pretty\",\n",
    "        order=model_order,\n",
    "        hue_order=pretty_order,\n",
    "        dodge=True,\n",
    "        alpha=0.4,\n",
    "        linewidth=0,\n",
    "        size=6,\n",
    "        palette=palette,\n",
    "        ax=ax,\n",
    "        zorder=3,\n",
    "    )\n",
    "\n",
    "    # remove duplicate legend entries\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles = handles[:len(pretty_order)]\n",
    "    labels = labels[:len(pretty_order)]\n",
    "\n",
    "    band_proxy = None\n",
    "    line_proxy = None\n",
    "\n",
    "    if random_band is not None and metric in random_band:\n",
    "        y_mean, y_low, y_high = random_band[metric]\n",
    "        y_mean = float(y_mean)\n",
    "        y_low = float(y_low)\n",
    "        y_high = float(y_high)\n",
    "\n",
    "        # color and style for random baseline\n",
    "        band_color = \"0.9\"   # 浅灰\n",
    "        band_alpha = 0.5\n",
    "        line_color = \"0.3\"   # 深灰\n",
    "        line_alpha = 0.9\n",
    "        line_width = 1.5\n",
    "        line_style = \"--\"\n",
    "\n",
    "        x_min, x_max = -0.5, len(model_order) - 0.5\n",
    "\n",
    "        ax.fill_between(\n",
    "            [x_min, x_max],\n",
    "            [y_low, y_low],\n",
    "            [y_high, y_high],\n",
    "            color=band_color,\n",
    "            alpha=band_alpha,\n",
    "            zorder=0,\n",
    "        )\n",
    "\n",
    "        ax.hlines(\n",
    "            y_mean,\n",
    "            x_min,\n",
    "            x_max,\n",
    "            colors=line_color,\n",
    "            linestyles=line_style,\n",
    "            linewidth=line_width,\n",
    "            alpha=line_alpha,\n",
    "            zorder=1,\n",
    "        )\n",
    "\n",
    "        band_proxy = Patch(\n",
    "            facecolor=band_color,\n",
    "            edgecolor=\"none\",\n",
    "            alpha=band_alpha,\n",
    "        )\n",
    "        line_proxy = Line2D(\n",
    "            [0], [0],\n",
    "            color=line_color,\n",
    "            linestyle=line_style,\n",
    "            linewidth=line_width,\n",
    "        )\n",
    "\n",
    "    if band_proxy is not None and line_proxy is not None:\n",
    "        handles = handles + [band_proxy, line_proxy]\n",
    "        labels = labels + [\"Random 95% CI\", \"Random mean\"]\n",
    "\n",
    "    ax.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        title=\"Task\",\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(0.98, 0.98),\n",
    "        borderaxespad=0.,\n",
    "        fontsize=12,\n",
    "        title_fontsize=15,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"\")\n",
    "    if metric == \"EDV_MAE\":\n",
    "        ax.set_ylabel(\"EDV MAE\", fontsize=15)\n",
    "    elif metric == \"ESV_MAE\":\n",
    "        ax.set_ylabel(\"ESV MAE\", fontsize=15)\n",
    "\n",
    "    ax.tick_params(axis=\"x\", labelsize=15)\n",
    "    plt.xticks(rotation=20, ha=\"center\", fontsize=15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f4ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage\n",
    "reg_all = pd.read_csv(\"your/path/to/regression_metrics.csv\")\n",
    "task_order = [\n",
    "    'edv_esv_video', 'esv_edv_video','edv_video','esv_video', \n",
    "    'segmented_edv_esv_video', 'segmented_esv_edv_video','segmented_edv_video','segmented_esv_video', \n",
    "    'non_medical_edv_esv_video','non_medical_esv_edv_video', 'non_medical_edv_video','non_medical_esv_video'    \n",
    "]\n",
    "task_order = [t for t in task_order if t in reg_all[\"task_group\"].unique()]\n",
    "\n",
    "# set your display names\n",
    "task_pretty = {\n",
    "    \"edv_esv_video\": \"EDV+ESV\",\n",
    "    'esv_edv_video': \"ESV+EDV\",\n",
    "    \"edv_video\": \"EDV-only\",\n",
    "    \"esv_video\": \"ESV-only\",\n",
    "    \"segmented_edv_esv_video\": \"Segm EDV+ESV\",\n",
    "    'segmented_esv_edv_video': \"Segm ESV+EDV\",\n",
    "    \"segmented_edv_video\": \"Segm EDV\",\n",
    "    \"segmented_esv_video\": \"Segm ESV\",\n",
    "    'non_medical_edv_esv_video': \"Non-med EDV+ESV\",\n",
    "    'non_medical_esv_edv_video': \"Non-med ESV+EDV\",\n",
    "    \"non_medical_edv_video\": \"Non-med EDV\",\n",
    "    \"non_medical_esv_video\": \"Non-med ESV\",\n",
    "}\n",
    "reg_all[\"task_group_pretty\"] = reg_all[\"task_group\"].map(\n",
    "    lambda x: task_pretty.get(x, x)\n",
    ")\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "palette = sns.color_palette(\"Set2\", n_colors=len(task_order))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b2fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_random_edv = 11.873749\n",
    "low_95_edv = 10.28\n",
    "high_95_edv = 13.53\n",
    "\n",
    "mean_random_esv = 11.616163999999998\n",
    "low_95_esv = 10.02\n",
    "high_95_esv = 13.22\n",
    "\n",
    "random_band = {\n",
    "    \"EDV_MAE\": (mean_random_edv, low_95_edv, high_95_edv),\n",
    "    \"ESV_MAE\": (mean_random_esv, low_95_esv, high_95_esv),\n",
    "}\n",
    "\n",
    "out_dir = metrics_dir / \"mae_boxplots_all_models\"\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "reg_metrics = [\n",
    "    \"EDV_MAE\",\n",
    "    \"ESV_MAE\",\n",
    "]\n",
    "\n",
    "for m in reg_metrics:\n",
    "    plot_reg_metric_all_models_tasks(\n",
    "        df=reg_all,\n",
    "        metric=m,\n",
    "        task_order=task_order,\n",
    "        model_order=['LLaVA-Interleave', 'LLaVA-NeXT-Video-7B', 'LLaVA-NeXT-Video-34B','Gemma-3n',\n",
    "                       'Qwen3-VL-8B', 'Qwen3-VL-32B'], \n",
    "        palette=palette,\n",
    "        save_path=out_dir / f\"seaborn_all_models_{m}.png\",\n",
    "        random_band=random_band\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
